import requests
from bs4 import BeautifulSoup
import re
import os
import time
import random
import json
from datetime import datetime, timedelta
import colorgram
from PIL import Image

# ==================== é…ç½®åŒºåŸŸ ====================

# 1. Bangumi ç”¨æˆ·ID
USER_ID = '950475'

# 2. ç­›é€‰æ¡ä»¶ (æ ¸å¿ƒé…ç½®)
FILTER_AIR_YEAR_MONTH = '2025-07' # æ ¼å¼: 'YYYY-MM'

# 3. Headers 
SCRAPE_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}
API_HEADERS = {
    'User-Agent': 'MyAnimePosterDownloader/1.1 (https://github.com/ienone)'
}

# 4. éœ€è¦çˆ¬å–çš„çŠ¶æ€
STATUSES = ['collect', 'on_hold', 'dropped']

# 5. ä»£ç†è®¾ç½® (å¦‚æœä¸éœ€è¦ä»£ç†ï¼Œè¯·å°† PROXY è®¾ç½®ä¸º None)
PROXY = {
    'http': 'http://127.0.0.1:7890',
    'https': 'http://127.0.0.1:7890'
}
# PROXY = None 

# 6. å›¾ç‰‡å¤„ç†é…ç½®
MAX_POSTER_WIDTH = 1200  # æµ·æŠ¥ä¿å­˜æ—¶çš„æœ€å¤§å®½åº¦
COLOR_SAMPLING_WIDTH = 480  # é¢œè‰²æå–æ—¶çš„é‡‡æ ·å®½åº¦

# ==================== å·¥å…·å‡½æ•° ====================

def setup_directory(dir_name):
    if not os.path.exists(dir_name):
        os.makedirs(dir_name)
        print(f"âœ… å·²åˆ›å»ºç›®å½•: {dir_name}")

def sanitize_filename(filename):
    return re.sub(r'[\\/*?:"<>|]', "", filename).strip()

def parse_date(date_str):
    if not date_str or date_str == "Unknown":
        return None
    date_str = date_str.replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
    formats = ['%Y-%m-%d', '%Y-%m']
    for fmt in formats:
        try:
            return datetime.strptime(date_str.strip(), fmt)
        except ValueError:
            continue
    try:
        return datetime.strptime(date_str.strip(), '%Y')
    except ValueError:
        pass
    return None

def parse_rating_date(date_str):
    """è§£ææ”¶è—æ—¥æœŸï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
    if not date_str:
        return None
    
    # ç§»é™¤å¯èƒ½çš„é¢å¤–æ–‡æœ¬
    date_str = date_str.strip()
    
    # å°è¯•å„ç§æ—¥æœŸæ ¼å¼
    patterns = [
        (r'(\d{4}-\d{1,2}-\d{1,2})', '%Y-%m-%d'),
        (r'(\d{4}/\d{1,2}/\d{1,2})', '%Y/%m/%d'),
        (r'(\d{4}-\d{1,2})', '%Y-%m'),
        (r'(\d{4}/\d{1,2})', '%Y/%m'),
    ]
    
    for pattern, fmt in patterns:
        match = re.search(pattern, date_str)
        if match:
            try:
                return datetime.strptime(match.group(1), fmt)
            except ValueError:
                continue
    
    return None

def get_date_range(target_month_str):
    """æ ¹æ®ç›®æ ‡æœˆä»½ç”Ÿæˆæ”¶è—æ—¥æœŸç­›é€‰åŒºé—´ï¼ˆç›®æ ‡æœˆ + å¾€å4ä¸ªæœˆï¼‰"""
    year, month = map(int, target_month_str.split('-'))
    start_date = datetime(year, month, 1)
    
    # è®¡ç®—ç»“æŸæ—¥æœŸï¼šå¾€å4ä¸ªæœˆçš„æœˆæœ«
    end_month = month + 3
    end_year = year
    if end_month > 12:
        end_year += end_month // 12
        end_month = end_month % 12
        if end_month == 0:
            end_month = 12
            end_year -= 1
    
    # è·å–è¯¥æœˆçš„æœ€åä¸€å¤©
    if end_month == 12:
        next_month_start = datetime(end_year + 1, 1, 1)
    else:
        next_month_start = datetime(end_year, end_month + 1, 1)
    end_date = next_month_start - timedelta(days=1)
    
    return start_date, end_date

def should_stop_pagination(rating_date_str, start_date):
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥åœæ­¢åˆ†é¡µï¼ˆé‡åˆ°æ—©äºèµ·å§‹æ—¥æœŸçš„æ¡ç›®ï¼‰"""
    rating_date = parse_rating_date(rating_date_str)
    if rating_date and rating_date < start_date:
        return True
    return False

def get_season_info(target_month_str):
    """æ ¹æ®ç›®æ ‡æœˆä»½è·å–å­£åº¦ä¿¡æ¯"""
    year, month = map(int, target_month_str.split('-'))
    
    # å®šä¹‰å­£åº¦åŒºé—´
    if month in [1, 2, 3]:
        season_name = "å†¬å­£"
        season_months = [1, 2, 3]
    elif month in [4, 5, 6]:
        season_name = "æ˜¥å­£" 
        season_months = [4, 5, 6]
    elif month in [7, 8, 9]:
        season_name = "å¤å­£"
        season_months = [7, 8, 9]
    else:  # [10, 11, 12]
        season_name = "ç§‹å­£"
        season_months = [10, 11, 12]
    
    return {
        'year': year,
        'season_name': season_name,
        'season_months': season_months,
        'start_month': season_months[0],
        'end_month': season_months[-1]
    }

def categorize_anime(air_date_str, target_month_str):
    """æ ¹æ®é¦–æ’­æ—¥æœŸåˆ†ç±»ç•ªå‰§"""
    air_date = parse_date(air_date_str)
    if not air_date:
        return "unknown"
    
    season_info = get_season_info(target_month_str)
    target_year = season_info['year']
    season_months = season_info['season_months']
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºå½“å­£æ–°ç•ª
    if (air_date.year == target_year and 
        air_date.month in season_months):
        return "current_season"  # å½“å­£æ–°ç•ª
    
    # è®¡ç®—ä¸Šä¸€ä¸ªå­£åº¦çš„æœˆä»½èŒƒå›´
    current_season_start = datetime(target_year, season_months[0], 1)
    
    # ä¸Šä¸€ä¸ªå­£åº¦ï¼ˆ3ä¸ªæœˆå‰ï¼‰
    if season_months[0] == 1:  # å½“å‰å†¬å­£ï¼Œä¸Šä¸€å­£åº¦æ˜¯å»å¹´ç§‹å­£
        prev_season_months = [10, 11, 12]
        prev_season_year = target_year - 1
    elif season_months[0] == 4:  # å½“å‰æ˜¥å­£ï¼Œä¸Šä¸€å­£åº¦æ˜¯å†¬å­£
        prev_season_months = [1, 2, 3]
        prev_season_year = target_year
    elif season_months[0] == 7:  # å½“å‰å¤å­£ï¼Œä¸Šä¸€å­£åº¦æ˜¯æ˜¥å­£
        prev_season_months = [4, 5, 6]
        prev_season_year = target_year
    else:  # season_months[0] == 10ï¼Œå½“å‰ç§‹å­£ï¼Œä¸Šä¸€å­£åº¦æ˜¯å¤å­£
        prev_season_months = [7, 8, 9]
        prev_season_year = target_year
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºä¸Šä¸€å­£åº¦ç•ªå‰§ï¼ˆè¿‘æœŸç•ªå‰§ï¼‰
    if (air_date.year == prev_season_year and 
        air_date.month in prev_season_months):
        return "recent_anime"  # è¿‘æœŸç•ªå‰§ï¼ˆä¸Šä¸€å­£åº¦ï¼‰
    
    # å…¶ä»–éƒ½å½’ç±»ä¸ºè¡¥æ—§ç•ª
    return "old_anime"  # è¡¥æ—§ç•ª

def extract_air_date(info_text):
    info_text = info_text.strip()
    patterns = [
        r'(\d{4}[å¹´/-]\d{1,2}[æœˆ/-]\d{1,2}æ—¥?)',
        r'(\d{4}å¹´\d{1,2}æœˆ)',
        r'(\d{4}-\d{2}-\d{2})',
        r'(\d{4}-\d{2})',
        r'(\d{4}å¹´)',
        r'(\d{4})'
    ]
    for pattern in patterns:
        match = re.search(pattern, info_text)
        if match:
            return match.group(1).replace('/', '-')
    return "Unknown"

def resize_image_with_aspect_ratio(image, max_width):
    """ä¿æŒé•¿å®½æ¯”ç¼©æ”¾å›¾ç‰‡åˆ°æŒ‡å®šæœ€å¤§å®½åº¦"""
    if image.width <= max_width:
        return image
    
    ratio = max_width / image.width
    new_height = int(image.height * ratio)
    return image.resize((max_width, new_height), Image.Resampling.LANCZOS)

def extract_dominant_rgb(image_path):
    """ä»å›¾ç‰‡æå–ä¸€ä¸ªç¾è§‚çš„ä¸»è‰²è°ƒï¼Œè¿”å›RGBå…ƒç»„ (r, g, b)"""
    if not image_path or not os.path.exists(image_path):
        return None
    try:
        # å…ˆç¼©æ”¾å›¾ç‰‡åˆ°è¾ƒå°å°ºå¯¸è¿›è¡Œé¢œè‰²é‡‡æ ·ï¼Œæå‡å¤„ç†é€Ÿåº¦
        with Image.open(image_path) as img:
            img = img.convert("RGB")
            sampled_img = resize_image_with_aspect_ratio(img, COLOR_SAMPLING_WIDTH)
            
        colors = colorgram.extract(sampled_img, 12)
        best_color = None
        max_score = -1
        for color in colors:
            hsl = color.hsl
            if hsl.s < 0.1 or hsl.l < 0.05 or hsl.l > 0.95:
                continue
            score = hsl.s - abs(hsl.l - 0.5)
            if score > max_score:
                max_score = score
                best_color = color.rgb
        if best_color:
            return best_color
        else:
            for color in sorted(colors, key=lambda c: c.proportion, reverse=True):
                if color.rgb.r > 10 and color.rgb.g > 10 and color.rgb.b > 10 and \
                   color.rgb.r < 245 and color.rgb.g < 245 and color.rgb.b < 245:
                    return color.rgb
        return colors[0].rgb
    except Exception as e:
        print(f"    âš ï¸ æå–é¢œè‰²å¤±è´¥ ({os.path.basename(image_path)}): {e}ã€‚")
        return None

def is_color_light(rgb_tuple):
    """æ ¹æ®W3Cäº®åº¦å…¬å¼åˆ¤æ–­é¢œè‰²æ˜¯æµ…è‰²è¿˜æ˜¯æ·±è‰²"""
    if not rgb_tuple:
        return False
    r, g, b = rgb_tuple
    luminance = (0.299 * r + 0.587 * g + 0.114 * b) / 255
    return luminance > 0.5 # äº®åº¦å¤§äº0.5è®¤ä¸ºæ˜¯æµ…è‰²

# ==================== æµ·æŠ¥ä¸‹è½½å‡½æ•° ====================

def download_poster(subject_id, title, poster_dir):
    api_url = f'https://api.bgm.tv/v0/subjects/{subject_id}/image?type=large'
    safe_title = sanitize_filename(title)
    
    try:
        response = requests.get(api_url, headers=API_HEADERS, proxies=PROXY, timeout=15, allow_redirects=True)
        response.raise_for_status()

        content_type = response.headers.get('Content-Type')
        extension = 'jpg'
        if content_type:
            if 'png' in content_type: extension = 'png'
            elif 'webp' in content_type: extension = 'webp'
            
        filename = f"{safe_title}_{subject_id}.{extension}"
        filepath = os.path.join(poster_dir, filename)
        
        # ä¸´æ—¶ä¿å­˜åŸå§‹å›¾ç‰‡
        temp_filepath = filepath + '.temp'
        with open(temp_filepath, 'wb') as f:
            f.write(response.content)
        
        # å¤„ç†å›¾ç‰‡ï¼šæ ¼å¼è½¬æ¢å’Œå°ºå¯¸ä¼˜åŒ–
        try:
            with Image.open(temp_filepath) as img:
                img = img.convert("RGB")
                
                # å¦‚æœå›¾ç‰‡å®½åº¦è¶…è¿‡é™åˆ¶ï¼Œåˆ™ç¼©æ”¾
                if img.width > MAX_POSTER_WIDTH:
                    img = resize_image_with_aspect_ratio(img, MAX_POSTER_WIDTH)
                    print(f"    ğŸ“ å›¾ç‰‡å·²ç¼©æ”¾è‡³å®½åº¦ {MAX_POSTER_WIDTH}px")
                
                # ä¿å­˜ä¸ºJPGæ ¼å¼
                final_filepath = os.path.join(poster_dir, f"{safe_title}_{subject_id}.jpg")
                img.save(final_filepath, "JPEG", quality=85, optimize=True)
                
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            os.remove(temp_filepath)
            print(f"    ğŸ–¼ï¸ æµ·æŠ¥å·²ä¸‹è½½å¹¶ä¼˜åŒ–: {os.path.basename(final_filepath)}")
            return final_filepath
            
        except Exception as e:
            # å¦‚æœå›¾ç‰‡å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶
            os.rename(temp_filepath, filepath)
            print(f"    âš ï¸ å›¾ç‰‡å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶: {e}")
            print(f"    ğŸ–¼ï¸ æµ·æŠ¥å·²ä¸‹è½½: {filename}")
            return filepath

    except requests.exceptions.RequestException as e:
        print(f"    âŒ ä¸‹è½½æµ·æŠ¥å¤±è´¥ (ID: {subject_id}): {e}")
        return None

# ==================== é¡µé¢è§£æå‡½æ•° (ä¿®æ”¹) ====================
def parse_page(soup, status, start_date, end_date, target_month):
    item_list_ul = soup.find('ul', id='browserItemList')
    if not item_list_ul: 
        return [], False
    
    items = item_list_ul.find_all('li', class_='item')
    results = []
    should_stop = False
    
    for item in items:
        try:
            h3 = item.find('h3')
            a_tag = h3.find('a', class_='l')
            title, link = a_tag.text.strip(), "https://bgm.tv" + a_tag['href']
            subject_id = re.search(r'/subject/(\d+)', link).group(1)
            info_tip_text = item.find('p', class_='info tip').text.strip() if item.find('p', class_='info tip') else ""
            air_date = extract_air_date(info_tip_text)
            
            collect_info = item.find('p', class_='collectInfo')
            rating, rating_date = 0, None
            if collect_info:
                date_tag = collect_info.find('span', class_='tip_j')
                if date_tag: 
                    rating_date = date_tag.text.strip()
                    
                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢åˆ†é¡µ
                    if should_stop_pagination(rating_date, start_date):
                        should_stop = True
                        break
                    
                    # æ£€æŸ¥æ”¶è—æ—¥æœŸæ˜¯å¦åœ¨ç›®æ ‡åŒºé—´å†…
                    rating_date_obj = parse_rating_date(rating_date)
                    if not rating_date_obj or rating_date_obj < start_date or rating_date_obj > end_date:
                        continue
                
                stars_tag = collect_info.find('span', class_=re.compile(r'stars\d+'))
                if stars_tag:
                    star_class = next((c for c in stars_tag.get('class', []) if c.startswith('stars')), None)
                    if star_class:
                        match = re.search(r'stars(\d+)', star_class)
                        if match: rating = int(match.group(1))
            
            # åˆ†ç±»ç•ªå‰§
            category = categorize_anime(air_date, target_month)
            if category == "unknown":
                continue  # è·³è¿‡æœªçŸ¥æ—¥æœŸçš„æ¡ç›®
                
            comment_box = item.find('div', id='comment_box')
            comment = comment_box.find('div', class_='text').text.strip() if comment_box and comment_box.find('div', class_='text') else None
            
            results.append({
                'subject_id': subject_id, 
                'title': title, 
                'link': link, 
                'air_date': air_date, 
                'rating_date': rating_date, 
                'rating_score': rating, 
                'comment': comment, 
                'status': status, 
                'category': category,
                'poster_path': None
            })
            
        except Exception as e:
            print(f"âŒ è§£ææŸä¸ªæ¡ç›®æ—¶å‡ºé”™ï¼Œå·²è·³è¿‡: {e}")
    
    return results, should_stop

# ==================== Markdown ç”Ÿæˆå‡½æ•° (ä¿®æ”¹) ====================

def generate_markdown_file(anime_data, output_dir):
    md_path = os.path.join(output_dir, "index.md")
    
    # åˆ†ç¦»ä¸åŒç±»å‹çš„ç•ªå‰§ï¼Œåªä¿ç•™å½“å­£æ–°ç•ªå’Œè¡¥æ—§ç•ª
    current_season = [item for item in anime_data if item['category'] == 'current_season']
    old_anime = [item for item in anime_data if item['category'] == 'old_anime']
    # è¿‘æœŸç•ªå‰§ä¸å±•ç¤ºï¼Œå› ä¸ºåº”è¯¥åœ¨ä¸Šä¸ªå­£åº¦å·²ç»è¢«æ€»ç»“è¿‡äº†
    
    # è·å–å­£åº¦ä¿¡æ¯
    season_info = get_season_info(FILTER_AIR_YEAR_MONTH)
    year = season_info['year']
    season_name = season_info['season_name']
    
    # 1. Front Matter
    title = f"{year}å¹´{season_name}æ–°ç•ªè§‚åç®€è¯„"
    today = datetime.now().strftime('%Y-%m-%d')
    
    front_matter = f"""---
title: "{title}"
date: {today}
description: "è®°å½•{year}å¹´{season_name}æ–°ç•ªä¸ªäººç®€è¯„ã€‚"
slug: "anime-review-{FILTER_AIR_YEAR_MONTH}"
tags: ["ç•ªå‰§", "å­£åº¦æ€»ç»“", "{year}å¹´", "{season_name}"]
series: ["å­£åº¦æ–°ç•ª"]
series_order: 1
showTableOfContents: true
---
"""

    # 2. æ¦‚è¿°
    overview = f"""
{{{{< lead >}}}}
åœ¨è¿™é‡Œå†™ä¸‹ä½ å¯¹æœ¬å­£æ–°ç•ªçš„æ€»ä½“æ¦‚è¿°å’Œçœ‹æ³•...
{{{{< /lead >}}}}

## ç®€å•æ€»ç»“
### {season_name}æ–°ç•ª
- æœ¬å­£åº¦æ–°ç•ªå…±çœ‹å®Œ {len([x for x in current_season if x['status'] == 'collect'])} éƒ¨ï¼Œå¼ƒç•ª {len([x for x in current_season if x['status'] == 'dropped'])} éƒ¨ï¼Œæç½® {len([x for x in current_season if x['status'] == 'on_hold'])} éƒ¨ã€‚

### è¡¥æ—§ç•ª
- è¡¥æ—§ç•ªå…± {len(old_anime)} éƒ¨ï¼š
{generate_old_anime_summary(old_anime)}

---

## {season_name}æ–°ç•ªè¯¦è¯„
"""
    
    # 3. ç”Ÿæˆå½“å­£æ–°ç•ªå¡ç‰‡
    current_season_content = ""
    for item in sorted(current_season, key=lambda x: x.get('rating_score', 0), reverse=True):
        if not item['poster_path']: 
            continue
        current_season_content += generate_anime_card(item)

    # 4. è¡¥æ—§ç•ªç®€è¦å±•ç¤º
    old_anime_section = ""
    if old_anime:
        old_anime_section = "\n## è¡¥æ—§ç•ªè®°å½•\n\n"
        for item in sorted(old_anime, key=lambda x: x.get('rating_score', 0), reverse=True):
            status_text = {'collect': 'çœ‹è¿‡', 'on_hold': 'æç½®', 'dropped': 'å¼ƒç•ª'}.get(item['status'], 'æœªçŸ¥')
            rating_text = f"{item['rating_score']}/10" if item['rating_score'] > 0 else "æœªè¯„åˆ†"
            old_anime_section += f"- [{item['title']}]({item['link']}) ({item['air_date']}) : {rating_text} ({status_text})\n"

    # 5. å†™å…¥æ–‡ä»¶
    try:
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(front_matter)
            f.write(overview)
            f.write(current_season_content)
            f.write(old_anime_section)
        print(f"\nğŸ‰ æˆåŠŸç”Ÿæˆ Markdown æ–‡ä»¶: {md_path}")
    except IOError as e:
        print(f"âŒ ä¿å­˜ Markdown æ–‡ä»¶å¤±è´¥: {e}")

def generate_old_anime_summary(old_anime_list):
    """ç”Ÿæˆè¡¥æ—§ç•ªæ¦‚è¿°"""
    if not old_anime_list:
        return "  - æœ¬æœŸé—´æœªè¡¥æ—§ç•ª"
    
    summary_lines = []
    for item in old_anime_list:
        rating_text = f"{item['rating_score']}/10" if item['rating_score'] > 0 else "æœªè¯„åˆ†"
        summary_lines.append(f"  - [{item['title']}]({item['link']}) ({item['air_date']}) : {rating_text}")
    
    return "\n".join(summary_lines)

def generate_anime_card(item):
    """ç”Ÿæˆå•ä¸ªç•ªå‰§å¡ç‰‡çš„HTML"""
    poster_filename = os.path.basename(item['poster_path'])
    poster_md_path = f"./bgm_posters/{poster_filename}"
    
    dominant_rgb = extract_dominant_rgb(item['poster_path'])
    
    if dominant_rgb:
        background_style = f"background-color: rgba({dominant_rgb.r}, {dominant_rgb.g}, {dominant_rgb.b}, 0.75);"
        is_light = is_color_light(dominant_rgb)
        link_class = 'text-gray-800 hover:text-sky-600' if is_light else 'text-white hover:text-sky-300'
        prose_class = 'prose' if is_light else 'prose prose-invert'
        border_class = 'border-gray-400/50' if is_light else 'border-gray-500/50'
        comment_bg_class = 'bg-black/10' if is_light else 'bg-white/10'
    else:
        background_style = "background-color: #374151;"
        link_class = 'text-white hover:text-sky-300'
        prose_class = 'prose prose-invert'
        border_class = 'border-gray-500/50'
        comment_bg_class = 'bg-white/10'

    status_text = {'collect': 'çœ‹è¿‡', 'on_hold': 'æç½®', 'dropped': 'å¼ƒç•ª'}.get(item['status'], 'æœªçŸ¥')
    rating_text = f"<strong>{item['rating_score']}/10</strong>" if item['rating_score'] > 0 else "æœªè¯„åˆ†"
    comment = item['comment'].replace('\r\n', '<br>').replace('\n', '<br>') if item['comment'] else "æš‚æ— çŸ­è¯„ã€‚"
    
    return f"""
### {item['title']}

<div class="mb-8 p-4 border rounded-lg dark:border-neutral-700" style="{background_style}">
    <div class="flex flex-col sm:flex-row gap-4">
        <!-- æµ·æŠ¥åŒºåŸŸ -->
        <div class="w-full sm:w-1/4 flex-shrink-0 flex justify-center items-start">
            <img src="{poster_md_path}" alt="{item['title']} æµ·æŠ¥" 
                class="rounded-md object-cover w-full max-w-xs mx-auto shadow-md">
        </div>
        <!-- å†…å®¹åŒºåŸŸ -->
        <div class="w-full sm:w-3/4 {prose_class}">
            <!-- æ ‡é¢˜åŒºåŸŸ -->
            <div class="pb-3 border-b {border_class}">
                <h4 class="text-2xl font-bold">
                    <a href="{item['link']}" target="_blank" rel="noopener noreferrer" class="{link_class} transition-colors duration-200">
                        {item['title']}
                    </a>
                </h4>
                <div class="flex items-center mt-2 gap-4">
                    <div class="font-semibold flex items-center">
                        <span class="text-amber-400 flex items-center">{{{{< icon "star" >}}}}</span>
                        <span class="ml-1.5">{rating_text}</span>
                    </div>
                    <div>
                        <span class="font-medium">çŠ¶æ€:</span> {status_text}
                    </div>
                </div>
            </div>
            <!-- è¯„è®ºåŒºåŸŸ -->
            <div class="rounded-lg p-4 my-4 {comment_bg_class}">
                <div class="{prose_class} max-w-none leading-relaxed">
                    <p>{comment}</p>
                </div>
            </div>
            <!-- å…ƒä¿¡æ¯åŒºåŸŸ -->
            <div class="mt-4 pt-3 border-t {border_class} text-sm">
                <div class="flex flex-wrap gap-x-6 gap-y-2">
                    <div><span class="font-medium">æ”¾é€æ—¥æœŸ:</span> {item['air_date']}</div>
                    <div><span class="font-medium">è¯„ä»·æ—¥æœŸ:</span> {item['rating_date'] or 'æœªçŸ¥'}</div>
                </div>
            </div>
        </div>
    </div>
</div>

"""

# ==================== ä¸»å‡½æ•° (ä¿®æ”¹) ====================

def main():
    if not FILTER_AIR_YEAR_MONTH or not re.match(r'^\d{4}-\d{2}$', FILTER_AIR_YEAR_MONTH):
        print("âŒ é”™è¯¯: è¯·åœ¨è„šæœ¬ä¸­æ­£ç¡®è®¾ç½® FILTER_AIR_YEAR_MONTH (æ ¼å¼: YYYY-MM)ã€‚")
        return

    # è®¡ç®—æ—¥æœŸåŒºé—´
    start_date, end_date = get_date_range(FILTER_AIR_YEAR_MONTH)
    print(f"ğŸ“… æ”¶è—æ—¥æœŸç­›é€‰åŒºé—´: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")
    
    output_dir = f"anime-evaluate-{FILTER_AIR_YEAR_MONTH}"
    poster_dir = os.path.join(output_dir, "bgm_posters")
    
    setup_directory(output_dir)
    setup_directory(poster_dir)
    
    all_collected_data = []
    print("ğŸš€ å¼€å§‹çˆ¬å– Bangumi æ•°æ®...")

    for status in STATUSES:
        page, has_next_page = 1, True
        print(f"\n--- æ­£åœ¨å¤„ç†çŠ¶æ€: {status} ---")
        
        while has_next_page:
            url = f"https://bgm.tv/anime/list/{USER_ID}/{status}?page={page}"
            print(f"ğŸŒ è¯·æ±‚é¡µé¢: {url}")
            try:
                response = requests.get(url, headers=SCRAPE_HEADERS, proxies=PROXY, timeout=15)
                response.raise_for_status()
                response.encoding = 'utf-8'
                soup = BeautifulSoup(response.text, 'lxml')
                
                items, should_stop = parse_page(soup, status, start_date, end_date, FILTER_AIR_YEAR_MONTH)
                
                print(f"    æ‰¾åˆ° {len(items)} ä¸ªç¬¦åˆæ¡ä»¶çš„æ¡ç›®ã€‚")
                all_collected_data.extend(items)
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢åˆ†é¡µ
                if should_stop or not soup.find('a', class_='p', text='â€ºâ€º'):
                    has_next_page = False
                    if should_stop:
                        print(f"    â¹ï¸ é‡åˆ°æ—©äºç›®æ ‡åŒºé—´çš„æ¡ç›®ï¼Œåœæ­¢éå† {status}")
                
                page += 1
                time.sleep(1)
            except requests.exceptions.RequestException as e:
                print(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}ã€‚åœæ­¢å¤„ç† {status}ã€‚")
                has_next_page = False
    
    print(f"\nâœ… çˆ¬å–å®Œæˆã€‚å…±è·å– {len(all_collected_data)} ä¸ªæ¡ç›®ã€‚")
    
    if not all_collected_data:
        print("\nâ¹ï¸ æœªæ‰¾åˆ°ä»»ä½•ç¬¦åˆæ¡ä»¶çš„ç•ªå‰§ã€‚è„šæœ¬æ‰§è¡Œç»“æŸã€‚")
        return
    
    # å…ˆè¿›è¡Œåˆ†ç±»ç»Ÿè®¡
    current_season = [item for item in all_collected_data if item['category'] == 'current_season']
    old_anime = [item for item in all_collected_data if item['category'] == 'old_anime']
    recent_anime = [item for item in all_collected_data if item['category'] == 'recent_anime']
    
    print(f"\nğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
    print(f"  - å½“å­£æ–°ç•ª: {len(current_season)} éƒ¨")
    print(f"  - è¿‘æœŸç•ªå‰§: {len(recent_anime)} éƒ¨ (ä¸ä¸‹è½½æµ·æŠ¥)")
    print(f"  - è¡¥æ—§ç•ª: {len(old_anime)} éƒ¨ (ä¸ä¸‹è½½æµ·æŠ¥)")
    
    # åªä¸ºå½“å­£æ–°ç•ªä¸‹è½½æµ·æŠ¥
    if current_season:
        print(f"\nğŸ–¼ï¸ å¼€å§‹ä¸ºå½“å­£æ–°ç•ªä¸‹è½½æµ·æŠ¥...")
        for item in current_season:
            print(f"â¬‡ï¸ å¤„ç†: {item['title']}")
            poster_path = download_poster(item['subject_id'], item['title'], poster_dir)
            item['poster_path'] = poster_path
            time.sleep(0.5)
    else:
        print("\nâš ï¸ æ²¡æœ‰å½“å­£æ–°ç•ªéœ€è¦ä¸‹è½½æµ·æŠ¥ã€‚")
    
    # ä¸ºè¡¥æ—§ç•ªå’Œè¿‘æœŸç•ªå‰§è®¾ç½®ç©ºçš„æµ·æŠ¥è·¯å¾„
    for item in old_anime + recent_anime:
        item['poster_path'] = None

    # ç”ŸæˆMarkdownæ–‡ä»¶
    valid_items = [item for item in all_collected_data if item['category'] == 'current_season' and item['poster_path']] + old_anime
    print(f"\nâœ… å¤„ç†å®Œæˆã€‚æœ‰æ•ˆæ¡ç›® {len(valid_items)} ä¸ªï¼ˆå½“å­£æ–°ç•ª: {len([x for x in valid_items if x['category'] == 'current_season'])}, è¡¥æ—§ç•ª: {len(old_anime)}ï¼‰ã€‚")
    
    generate_markdown_file(valid_items, output_dir)

if __name__ == "__main__":
    main()