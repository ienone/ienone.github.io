import requests
from bs4 import BeautifulSoup
import re
import os
import time
import random
import json
from datetime import datetime
import colorgram
from PIL import Image

# ==================== é…ç½®åŒºåŸŸ ====================

# 1. Bangumi ç”¨æˆ·ID
USER_ID = '950475'

# 2. ç­›é€‰æ¡ä»¶ (æ ¸å¿ƒé…ç½®)
FILTER_AIR_YEAR_MONTH = '2025-04' # æ ¼å¼: 'YYYY-MM'

# 3. Headers 
SCRAPE_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}
API_HEADERS = {
    'User-Agent': 'MyAnimePosterDownloader/1.1 (https://github.com/ienone)'
}

# 4. éœ€è¦çˆ¬å–çš„çŠ¶æ€
STATUSES = ['collect', 'on_hold', 'dropped']

# 5. ä»£ç†è®¾ç½® (å¦‚æœä¸éœ€è¦ä»£ç†ï¼Œè¯·å°† PROXY è®¾ç½®ä¸º None)
PROXY = {
    'http': 'http://127.0.0.1:7890',
    'https': 'http://127.0.0.1:7890'
}
# PROXY = None 

# ==================== å·¥å…·å‡½æ•° ====================

def setup_directory(dir_name):
    if not os.path.exists(dir_name):
        os.makedirs(dir_name)
        print(f"âœ… å·²åˆ›å»ºç›®å½•: {dir_name}")

def sanitize_filename(filename):
    return re.sub(r'[\\/*?:"<>|]', "", filename).strip()

def parse_date(date_str):
    if not date_str or date_str == "Unknown":
        return None
    date_str = date_str.replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
    formats = ['%Y-%m-%d', '%Y-%m']
    for fmt in formats:
        try:
            return datetime.strptime(date_str.strip(), fmt)
        except ValueError:
            continue
    try:
        return datetime.strptime(date_str.strip(), '%Y')
    except ValueError:
        pass
    return None

def extract_air_date(info_text):
    info_text = info_text.strip()
    patterns = [
        r'(\d{4}[å¹´/-]\d{1,2}[æœˆ/-]\d{1,2}æ—¥?)',
        r'(\d{4}å¹´\d{1,2}æœˆ)',
        r'(\d{4}-\d{2}-\d{2})',
        r'(\d{4}-\d{2})',
        r'(\d{4}å¹´)',
        r'(\d{4})'
    ]
    for pattern in patterns:
        match = re.search(pattern, info_text)
        if match:
            return match.group(1).replace('/', '-')
    return "Unknown"

# def extract_dominant_rgb(image_path):
#     """ä¼˜åŒ–ç‰ˆä¸»è‰²æå–"""
#     if not os.path.exists(image_path):
#         return None
    
#     try:
#         # å…ˆç¼©å°å›¾ç‰‡å°ºå¯¸å†æå–é¢œè‰²
#         img = Image.open(image_path)
        
#         # è½¬æ¢ä¸ºRGBå¦‚æœè¿˜ä¸æ˜¯
#         if img.mode != 'RGB':
#             img = img.convert('RGB')
            
#         # ç›´æ¥é‡‡æ ·éƒ¨åˆ†åƒç´ è€Œä¸æ˜¯åˆ†æå…¨éƒ¨
#         pixels = list(img.getdata())
#         sample_size = min(500, len(pixels))
#         sampled_pixels = random.sample(pixels, sample_size)
        
#         # ç®€å•çš„é¢œè‰²èšç±»
#         from collections import defaultdict
#         color_groups = defaultdict(list)
#         for r, g, b in sampled_pixels:
#             # å°†é¢œè‰²åˆ†ç»„åˆ°è¾ƒå¤§çš„åŒºé—´
#             key = (r//16, g//16, b//16)
#             color_groups[key].append((r, g, b))
            
#         # æ‰¾å‡ºæœ€å¤§çš„é¢œè‰²ç»„
#         largest_group = max(color_groups.values(), key=len)
#         avg_color = tuple(int(sum(x)/len(x)) for x in zip(*largest_group))
        
#         return avg_color
        
#     except Exception as e:
#         print(f"âš ï¸ æå–é¢œè‰²å¤±è´¥: {e}")
#         return None

def extract_dominant_rgb(image_path):
    """ä»å›¾ç‰‡æå–ä¸€ä¸ªç¾è§‚çš„ä¸»è‰²è°ƒï¼Œè¿”å›RGBå…ƒç»„ (r, g, b)"""
    if not image_path or not os.path.exists(image_path):
        return None
    try:
        colors = colorgram.extract(image_path, 12)
        best_color = None
        max_score = -1
        for color in colors:
            hsl = color.hsl
            if hsl.s < 0.1 or hsl.l < 0.05 or hsl.l > 0.95:
                continue
            score = hsl.s - abs(hsl.l - 0.5)
            if score > max_score:
                max_score = score
                best_color = color.rgb
        if best_color:
            return best_color
        else:
            for color in sorted(colors, key=lambda c: c.proportion, reverse=True):
                if color.rgb.r > 10 and color.rgb.g > 10 and color.rgb.b > 10 and \
                   color.rgb.r < 245 and color.rgb.g < 245 and color.rgb.b < 245:
                    return color.rgb
        return colors[0].rgb
    except Exception as e:
        print(f"    âš ï¸ æå–é¢œè‰²å¤±è´¥ ({os.path.basename(image_path)}): {e}ã€‚")
        return None

def is_color_light(rgb_tuple):
    """æ ¹æ®W3Cäº®åº¦å…¬å¼åˆ¤æ–­é¢œè‰²æ˜¯æµ…è‰²è¿˜æ˜¯æ·±è‰²"""
    if not rgb_tuple:
        return False
    r, g, b = rgb_tuple
    luminance = (0.299 * r + 0.587 * g + 0.114 * b) / 255
    return luminance > 0.5 # äº®åº¦å¤§äº0.5è®¤ä¸ºæ˜¯æµ…è‰²

# ==================== æµ·æŠ¥ä¸‹è½½å‡½æ•° ====================

def download_poster(subject_id, title, poster_dir):
    api_url = f'https://api.bgm.tv/v0/subjects/{subject_id}/image?type=large'
    safe_title = sanitize_filename(title)
    
    try:
        response = requests.get(api_url, headers=API_HEADERS, proxies=PROXY, timeout=15, allow_redirects=True)
        response.raise_for_status()

        content_type = response.headers.get('Content-Type')
        extension = 'jpg'
        if content_type:
            if 'png' in content_type: extension = 'png'
            elif 'webp' in content_type: extension = 'webp'
            
        filename = f"{safe_title}_{subject_id}.{extension}"
        filepath = os.path.join(poster_dir, filename)
        
        with open(filepath, 'wb') as f:
            f.write(response.content)
        
        if extension == 'webp':
            try:
                img = Image.open(filepath).convert("RGB")
                new_filepath = os.path.join(poster_dir, f"{safe_title}_{subject_id}.jpg")
                img.save(new_filepath, "jpeg")
                os.remove(filepath)
                print(f"    ğŸ–¼ï¸ æµ·æŠ¥å·²ä¸‹è½½å¹¶è½¬æ¢ä¸ºJPG: {os.path.basename(new_filepath)}")
                return new_filepath
            except Exception as e:
                print(f"    âš ï¸ WebPè½¬æ¢å¤±è´¥: {e}ã€‚")

        print(f"    ğŸ–¼ï¸ æµ·æŠ¥å·²ä¸‹è½½: {filename}")
        return filepath

    except requests.exceptions.RequestException as e:
        print(f"    âŒ ä¸‹è½½æµ·æŠ¥å¤±è´¥ (ID: {subject_id}): {e}")
        return None

# ==================== é¡µé¢è§£æå‡½æ•° (ä¿æŒä¸å˜) ====================
def parse_page(soup, status):
    item_list_ul = soup.find('ul', id='browserItemList')
    if not item_list_ul: return []
    items = item_list_ul.find_all('li', class_='item')
    results = []
    for item in items:
        try:
            h3 = item.find('h3')
            a_tag = h3.find('a', class_='l')
            title, link = a_tag.text.strip(), "https://bgm.tv" + a_tag['href']
            subject_id = re.search(r'/subject/(\d+)', link).group(1)
            info_tip_text = item.find('p', class_='info tip').text.strip() if item.find('p', class_='info tip') else ""
            air_date = extract_air_date(info_tip_text)
            collect_info = item.find('p', class_='collectInfo')
            rating, rating_date = 0, None
            if collect_info:
                date_tag = collect_info.find('span', class_='tip_j')
                if date_tag: rating_date = date_tag.text.strip()
                stars_tag = collect_info.find('span', class_=re.compile(r'stars\d+'))
                if stars_tag:
                    star_class = next((c for c in stars_tag.get('class', []) if c.startswith('stars')), None)
                    if star_class:
                        match = re.search(r'stars(\d+)', star_class)
                        if match: rating = int(match.group(1))
            comment_box = item.find('div', id='comment_box')
            comment = comment_box.find('div', class_='text').text.strip() if comment_box and comment_box.find('div', class_='text') else None
            results.append({'subject_id': subject_id, 'title': title, 'link': link, 'air_date': air_date, 'rating_date': rating_date, 'rating_score': rating, 'comment': comment, 'status': status, 'poster_path': None})
        except Exception as e:
            print(f"âŒ è§£ææŸä¸ªæ¡ç›®æ—¶å‡ºé”™ï¼Œå·²è·³è¿‡: {e}")
    return results

# ==================== Markdown ç”Ÿæˆå‡½æ•°====================

def generate_markdown_file(anime_list, output_dir):
    md_path = os.path.join(output_dir, "index.md")
    
    # 1. Front Matter (æ— å˜åŒ–)
    year, month = FILTER_AIR_YEAR_MONTH.split('-')
    title = f"{year}å¹´{month}æœˆæ–°ç•ªè§‚åç®€è¯„"
    today = datetime.now().strftime('%Y-%m-%d')
    
    front_matter = f"""---
title: "{title}"
date: {today}
description: "è®°å½•{year}å¹´{month}æœˆæ–°ç•ªä¸ªäººç®€è¯„ã€‚"
slug: "anime-review-{FILTER_AIR_YEAR_MONTH}"
tags: ["ç•ªå‰§", "å­£åº¦æ€»ç»“", "{year}å¹´"]
series: ["å­£åº¦æ–°ç•ª"]
series_order: 1
showTableOfContents: true
---
"""

    # 2. æ¦‚è¿°
    overview = """
{{< lead >}}
åœ¨è¿™é‡Œå†™ä¸‹ä½ å¯¹æœ¬å­£æ–°ç•ªçš„æ€»ä½“æ¦‚è¿°å’Œçœ‹æ³•...
{{< /lead >}}

---
"""
    
    # 3. ç”Ÿæˆå¡ç‰‡
    cards_content = ""
    for item in anime_list:
        if not item['poster_path']: continue

        cards_content += f"\n### {item['title']}\n\n"
        
        poster_filename = os.path.basename(item['poster_path'])
        poster_md_path = f"./bgm_posters/{poster_filename}"
        
        dominant_rgb = extract_dominant_rgb(item['poster_path'])
        
        if dominant_rgb:
            background_style = f"background-color: rgba({dominant_rgb.r}, {dominant_rgb.g}, {dominant_rgb.b}, 0.75);"
            # background_style = f"background-color: rgba({dominant_rgb[0]}, {dominant_rgb[1]}, {dominant_rgb[2]}, 0.75);"
            is_light = is_color_light(dominant_rgb)
            link_class = 'text-gray-800 hover:text-sky-600' if is_light else 'text-white hover:text-sky-300'
            prose_class = 'prose' if is_light else 'prose prose-invert'
            border_class = 'border-gray-400/50' if is_light else 'border-gray-500/50'
            comment_bg_class = 'bg-black/10' if is_light else 'bg-white/10'
        else:
            background_style = "background-color: #374151;"
            link_class = 'text-white hover:text-sky-300'
            prose_class = 'prose prose-invert'
            border_class = 'border-gray-500/50'
            comment_bg_class = 'bg-white/10'

        status_text = {'collect': 'çœ‹è¿‡', 'on_hold': 'æç½®', 'dropped': 'å¼ƒç•ª'}.get(item['status'], 'æœªçŸ¥')
        rating_text = f"<strong>{item['rating_score']}/10</strong>" if item['rating_score'] > 0 else "æœªè¯„åˆ†"
        comment = item['comment'].replace('\r\n', '<br>').replace('\n', '<br>') if item['comment'] else "æš‚æ— çŸ­è¯„ã€‚"
        card_html = f"""
<div class="mb-8 p-4 border rounded-lg dark:border-neutral-700" style="{background_style}">
    <div class="flex flex-col sm:flex-row gap-4">
        <!-- æµ·æŠ¥åŒºåŸŸ -->
        <div class="w-full sm:w-1/4 flex-shrink-0 flex justify-center items-start">
            <img src="{poster_md_path}" alt="{item['title']} æµ·æŠ¥" 
                class="rounded-md object-cover w-full max-w-xs mx-auto shadow-md">
        </div>
        <!-- å†…å®¹åŒºåŸŸ -->
        <div class="w-full sm:w-3/4 {prose_class}">
            <!-- æ ‡é¢˜åŒºåŸŸ -->
            <div class="pb-3 border-b {border_class}">
                <h4 class="text-2xl font-bold">
                    <a href="{item['link']}" target="_blank" rel="noopener noreferrer" class="{link_class} transition-colors duration-200">
                        {item['title']}
                    </a>
                </h4>
                <div class="flex items-center mt-2 gap-4">
                    <div class="font-semibold flex items-center">
                        <span class="text-amber-400 flex items-center">{{{{< icon "star" >}}}}</span>
                        <span class="ml-1.5">{rating_text}</span>
                    </div>
                    <div>
                        <span class="font-medium">çŠ¶æ€:</span> {status_text}
                    </div>
                </div>
            </div>
            <!-- è¯„è®ºåŒºåŸŸ -->
            <div class="rounded-lg p-4 my-4 {comment_bg_class}">
                <div class="{prose_class} max-w-none leading-relaxed">
                    <p>{comment}</p>
                </div>
            </div>
            <!-- å…ƒä¿¡æ¯åŒºåŸŸ -->
            <div class="mt-4 pt-3 border-t {border_class} text-sm">
                <div class="flex flex-wrap gap-x-6 gap-y-2">
                    <div><span class="font-medium">æ”¾é€æ—¥æœŸ:</span> {item['air_date']}</div>
                    <div><span class="font-medium">è¯„ä»·æ—¥æœŸ:</span> {item['rating_date'] or 'æœªçŸ¥'}</div>
                </div>
            </div>
        </div>
    </div>
</div>
"""
        cards_content += card_html

    # 4. å†™å…¥æ–‡ä»¶ 
    try:
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(front_matter)
            f.write(overview)
            f.write(cards_content)
        print(f"\nğŸ‰ æˆåŠŸç”Ÿæˆ Markdown æ–‡ä»¶: {md_path}")
    except IOError as e:
        print(f"âŒ ä¿å­˜ Markdown æ–‡ä»¶å¤±è´¥: {e}")


def main():
    if not FILTER_AIR_YEAR_MONTH or not re.match(r'^\d{4}-\d{2}$', FILTER_AIR_YEAR_MONTH):
        print("âŒ é”™è¯¯: è¯·åœ¨è„šæœ¬ä¸­æ­£ç¡®è®¾ç½® FILTER_AIR_YEAR_MONTH (æ ¼å¼: YYYY-MM)ã€‚")
        return

    output_dir = f"anime-evaluate-{FILTER_AIR_YEAR_MONTH}"
    poster_dir = os.path.join(output_dir, "bgm_posters")
    
    setup_directory(output_dir)
    setup_directory(poster_dir)
    
    all_collected_data = []
    print("ğŸš€ å¼€å§‹çˆ¬å– Bangumi æ•°æ®...")

    for status in STATUSES:
        page, has_next_page = 1, True
        print(f"\n--- æ­£åœ¨å¤„ç†çŠ¶æ€: {status} ---")
        while has_next_page:
            url = f"https://bgm.tv/anime/list/{USER_ID}/{status}?page={page}"
            print(f"ğŸŒ è¯·æ±‚é¡µé¢: {url}")
            try:
                response = requests.get(url, headers=SCRAPE_HEADERS, proxies=PROXY, timeout=15)
                response.raise_for_status()
                response.encoding = 'utf-8'
                soup = BeautifulSoup(response.text, 'lxml')
                items = parse_page(soup, status)
                
                if not items or not soup.find('a', class_='p', text='â€ºâ€º'):
                    has_next_page = False
                
                print(f"    æ‰¾åˆ° {len(items)} ä¸ªæ¡ç›®ã€‚")
                all_collected_data.extend(items)
                page += 1
                time.sleep(1)
            except requests.exceptions.RequestException as e:
                print(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}ã€‚åœæ­¢å¤„ç† {status}ã€‚")
                has_next_page = False
    
    print(f"\nâœ… çˆ¬å–å®Œæˆã€‚å…±è·å– {len(all_collected_data)} ä¸ªæ¡ç›®ã€‚")
    print("\nğŸ” å¼€å§‹æ ¹æ®é…ç½®è¿›è¡Œç­›é€‰å’Œä¸‹è½½...")
    
    filtered_results = []
    for item in all_collected_data:
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ£€æŸ¥æ”¾é€æœˆä»½
        air_date_dt = parse_date(item['air_date'])
        if air_date_dt and f"{air_date_dt.year}-{air_date_dt.month:02d}" == FILTER_AIR_YEAR_MONTH:
            print(f"â¬‡ï¸  å¤„ç†ç¬¦åˆæ¡ä»¶çš„ç•ªå‰§: {item['title']}")
            poster_path = download_poster(item['subject_id'], item['title'], poster_dir)
            item['poster_path'] = poster_path
            filtered_results.append(item)
            time.sleep(0.5) # APIè°ƒç”¨ä¹Ÿéœ€è¦é™é€Ÿ

    if not filtered_results:
        print("\nâ¹ï¸  ç­›é€‰åæ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç¬¦åˆæ¡ä»¶çš„ç•ªå‰§ã€‚è„šæœ¬æ‰§è¡Œç»“æŸã€‚")
        return

    print(f"\nâœ… ç­›é€‰å’Œä¸‹è½½å®Œæˆã€‚å…±å¤„ç† {len(filtered_results)} ä¸ªç¬¦åˆæ¡ä»¶çš„ç•ªå‰§ã€‚")
    
    # æŒ‰è¯„åˆ†æ’åºåç”Ÿæˆæ–‡ä»¶
    generate_markdown_file(sorted(filtered_results, key=lambda x: x.get('rating_score', 0), reverse=True), output_dir)

if __name__ == "__main__":
    main()