import os
import re
import sys
import requests
from bs4 import BeautifulSoup

# --- é…ç½® ---
MARKDOWN_FILE = 'index.md'
OUTPUT_DIR = 'anime_posters_new' # æ–°çš„è¾“å‡ºç›®å½•ï¼Œé¿å…ä¸æ—§æ–‡ä»¶æ··æ·†
API_URL_TEMPLATE = 'https://api.bgm.tv/v0/subjects/{}/image?type=common'
HEADERS = {
    'User-Agent': 'MyAnimePosterDownloader/1.1 (https://github.com/ienone)'
}
# --- é…ç½®ç»“æŸ ---

def sanitize_filename(filename):
    """ç§»é™¤æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦ï¼Œè™½ç„¶ä»srcæå–çš„ä¸€èˆ¬æ˜¯å®‰å…¨çš„ï¼Œä½†ä»¥é˜²ä¸‡ä¸€ã€‚"""
    return re.sub(r'[\\/*?:"<>|]', "", filename).strip()

def setup_directory(dir_name):
    """åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰"""
    if not os.path.exists(dir_name):
        try:
            os.makedirs(dir_name)
            print(f"âœ… æˆåŠŸåˆ›å»ºç›®å½•: '{dir_name}'")
        except OSError as e:
            print(f"âŒ åˆ›å»ºç›®å½• '{dir_name}' å¤±è´¥: {e}")
            sys.exit(1)

def parse_and_download():
    """è§£æ Markdown æ–‡ä»¶å¹¶ä¸‹è½½æ‰€æœ‰ç•ªå‰§å›¾ç‰‡"""
    try:
        with open(MARKDOWN_FILE, 'r', encoding='utf-8') as f:
            content = f.read()
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°æ–‡ä»¶ '{MARKDOWN_FILE}'ã€‚è¯·ç¡®ä¿è„šæœ¬å’Œè¯¥æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚")
        sys.exit(1)

    soup = BeautifulSoup(content, 'lxml')
    
    anime_cards = soup.find_all('div', class_=re.compile(r'flex.*border.*rounded-lg'))
    
    if not anime_cards:
        print("âš ï¸ è­¦å‘Š: åœ¨æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ä»»ä½•ç•ªå‰§å¡ç‰‡ã€‚è¯·æ£€æŸ¥ HTML ç»“æ„æ˜¯å¦æ­£ç¡®ã€‚")
        return

    print(f"ğŸ” æ‰¾åˆ°äº† {len(anime_cards)} ä¸ªç•ªå‰§æ¡ç›®ï¼Œå¼€å§‹å¤„ç†...")
    
    for card in anime_cards:
        # å¯»æ‰¾åŒ…å« subject ID çš„é“¾æ¥
        link_tag = card.find('a', href=re.compile(r'bgm.tv/subject/'))
        # å¯»æ‰¾ <img> æ ‡ç­¾
        img_tag = card.find('img')
        
        if not link_tag or not img_tag:
            print("âš ï¸ è­¦å‘Š: å‘ç°ä¸€ä¸ªå¡ç‰‡ï¼Œä½†æ— æ³•æå–é“¾æ¥æˆ–å›¾ç‰‡æ ‡ç­¾ï¼Œå·²è·³è¿‡ã€‚")
            continue
            
        # ä»é“¾æ¥ä¸­æå– subject ID
        match_id = re.search(r'/subject/(\d+)', link_tag['href'])
        if not match_id:
            print(f"âš ï¸ è­¦å‘Š: åœ¨é“¾æ¥ '{link_tag['href']}' ä¸­æœªæ‰¾åˆ° subject IDï¼Œå·²è·³è¿‡ã€‚")
            continue
        subject_id = match_id.group(1)
        
        # ä» <img> æ ‡ç­¾çš„ src å±æ€§ä¸­æå–æ–‡ä»¶å
        src_path = img_tag.get('src', '')
        if not src_path:
             print(f"âš ï¸ è­¦å‘Š: æ‰¾åˆ°ä¸€ä¸ªå›¾ç‰‡æ ‡ç­¾ï¼Œä½†æ²¡æœ‰ 'src' å±æ€§ï¼Œå·²è·³è¿‡ã€‚ (ID: {subject_id})")
             continue
        # os.path.basename å¯ä»¥å®‰å…¨åœ°ä»è·¯å¾„ä¸­æå–æ–‡ä»¶å
        target_filename = os.path.basename(src_path)

        # ä¸‹è½½å›¾ç‰‡
        download_image(subject_id, target_filename)

def download_image(subject_id, target_filename):
    """æ ¹æ® subject ID å’Œç›®æ ‡æ–‡ä»¶åä¸‹è½½å›¾ç‰‡"""
    api_url = API_URL_TEMPLATE.format(subject_id)
    # ä»æ–‡ä»¶åä¸­æå–æ ‡é¢˜ï¼Œç”¨äºæ—¥å¿—æ‰“å°
    anime_title_log = os.path.splitext(target_filename)[0].replace('_', ' ').title()
    print(f"\nğŸš€ æ­£åœ¨å¤„ç†: '{anime_title_log}' (ID: {subject_id})")
    
    try:
        response = requests.get(api_url, headers=HEADERS, timeout=15)
        response.raise_for_status()

        # æ‹¼æ¥æœ€ç»ˆä¿å­˜è·¯å¾„
        safe_filename = sanitize_filename(target_filename)
        filepath = os.path.join(OUTPUT_DIR, safe_filename)
        
        # å†™å…¥æ–‡ä»¶
        with open(filepath, 'wb') as f:
            f.write(response.content)
        print(f"   - âœ… å›¾ç‰‡å·²ä¿å­˜ä¸º: '{filepath}'")

    except requests.exceptions.RequestException as e:
        print(f"   - âŒ ä¸‹è½½å¤±è´¥: {e}")

if __name__ == "__main__":
    print("--- Bangumi ç•ªå‰§æµ·æŠ¥ä¸‹è½½è„šæœ¬ ---")
    setup_directory(OUTPUT_DIR)
    parse_and_download()
    print("\n--- æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ ---")